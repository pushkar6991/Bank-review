{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#import required packages\n",
    "#basics\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "#misc\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "#stats\n",
    "#from scipy.misc import imread\n",
    "from scipy import sparse\n",
    "import scipy.stats as ss\n",
    "\n",
    "#viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#nlp\n",
    "import string\n",
    "import re    #for regex\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#import spacy\n",
    "from nltk import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tweet tokenizer does not split at apostophes which is what we want\n",
    "from nltk.tokenize import TweetTokenizer   \n",
    "\n",
    "#FeatureEngineering\n",
    "#!pip install lightgbm\n",
    "#from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, decomposition, ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import  textblob\n",
    "#import xgboost\n",
    "#from keras.preprocessing import text, sequence\n",
    "#from keras import layers, models, optimizers\n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from textblob import Word\n",
    "\n",
    "#settings\n",
    "start_time=time.time()\n",
    "color = sns.color_palette()\n",
    "sns.set_style(\"dark\")\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "tokenizer=TweetTokenizer()\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel('C:\\\\Users\\\\hp\\\\Desktop\\\\analytixlabs\\\\Ml case study\\\\text mining bank review\\\\BankReviews.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>BankName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Stars                                            Reviews  \\\n",
       "0 2017-04-10      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1 2017-02-10      5  Matthew Richardson is professional and helpful...   \n",
       "2 2017-08-21      5  We had a past experience with Wyndham Mortgage...   \n",
       "3 2017-12-17      5  We have been dealing with Brad Thomka from the...   \n",
       "4 2016-05-27      5  I can't express how grateful I am for the supp...   \n",
       "\n",
       "                   BankName  \n",
       "0  Wyndham Capital Mortgage  \n",
       "1  Wyndham Capital Mortgage  \n",
       "2  Wyndham Capital Mortgage  \n",
       "3  Wyndham Capital Mortgage  \n",
       "4  Wyndham Capital Mortgage  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data[['Stars','Reviews']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nI never write reviews but had to this time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nIt all started when Bob G ran a credit che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nWhat a horrible experience. We have excell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nRep was extremely professional, friendly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nI was working with a loan consultant from ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Stars                                            Reviews\n",
       "0        5  Great job, Wyndham Capital! Each person was pr...\n",
       "1        5  Matthew Richardson is professional and helpful...\n",
       "2        5  We had a past experience with Wyndham Mortgage...\n",
       "3        5  We have been dealing with Brad Thomka from the...\n",
       "4        5  I can't express how grateful I am for the supp...\n",
       "..     ...                                                ...\n",
       "500      1  \\r\\nI never write reviews but had to this time...\n",
       "501      1  \\r\\nIt all started when Bob G ran a credit che...\n",
       "502      1  \\r\\nWhat a horrible experience. We have excell...\n",
       "503      1  \\r\\nRep was extremely professional, friendly, ...\n",
       "504      1  \\r\\nI was working with a loan consultant from ...\n",
       "\n",
       "[505 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reviews'] = df['Reviews'].astype(str)\n",
    "df['count_sent'] = df[\"Reviews\"].apply(\n",
    "    lambda x: len(re.findall(\"\\n\", str(x))) + 1)\n",
    "\n",
    "#Word count in each comment:\n",
    "df['count_word'] = df[\"Reviews\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "#Unique word count\n",
    "df['count_unique_word'] = df[\"Reviews\"].apply(\n",
    "    lambda x: len(set(str(x).split())))\n",
    "\n",
    "#Letter count\n",
    "df['count_letters'] = df[\"Reviews\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "#Word density\n",
    "\n",
    "df['word_density'] = df['count_letters'] / (df['count_word'] + 1)\n",
    "\n",
    "#punctuation count\n",
    "df[\"count_punctuations\"] = df[\"Reviews\"].apply(\n",
    "    lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "#upper case words count\n",
    "df[\"count_words_upper\"] = df[\"Reviews\"].apply(\n",
    "    lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "\n",
    "#upper case words count\n",
    "df[\"count_words_lower\"] = df[\"Reviews\"].apply(\n",
    "    lambda x: len([w for w in str(x).split() if w.islower()]))\n",
    "\n",
    "#title case words count\n",
    "df[\"count_words_title\"] = df[\"Reviews\"].apply(\n",
    "    lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "\n",
    "#Number of stopwords\n",
    "df[\"count_stopwords\"] = df[\"Reviews\"].apply(\n",
    "    lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "\n",
    "#Average length of the words\n",
    "df[\"mean_word_len\"] = df[\"Reviews\"].apply(\n",
    "    lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "#Number of numeric\n",
    "df['numeric'] = df['Reviews'].apply(\n",
    "    lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "#Number of alphanumeric\n",
    "df['alphanumeric'] = df['Reviews'].apply(\n",
    "    lambda x: len([x for x in x.split() if x.isalnum()]))\n",
    "\n",
    "#Number of alphabetics\n",
    "df['alphabetetics'] = df['Reviews'].apply(\n",
    "    lambda x: len([x for x in x.split() if x.isalpha()]))\n",
    "\n",
    "#Number of alphabetics\n",
    "df['Spaces'] = df['Reviews'].apply(\n",
    "    lambda x: len([x for x in x.split() if x.isspace()]))\n",
    "\n",
    "#Number of Words ends with\n",
    "df['words_ends_with_et'] = df['Reviews'].apply(\n",
    "    lambda x: len([x for x in x.lower().split() if x.endswith('et')]))\n",
    "\n",
    "#Number of Words ends with\n",
    "df['words_start_with_no'] = df['Reviews'].apply(\n",
    "    lambda x: len([x for x in x.lower().split() if x.startswith('no')]))\n",
    "\n",
    "# Count the occurences of all words\n",
    "df['wordcounts'] = df['Reviews'].apply(\n",
    "    lambda x: dict([[t, x.split().count(t)] for t in set(x.split())]))\n",
    "\n",
    "pos_family = {\n",
    "    'noun': ['NN', 'NNS', 'NNP', 'NNPS'],\n",
    "    'pron': ['PRP', 'PRP$', 'WP', 'WP$'],\n",
    "    'verb': ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'],\n",
    "    'adj': ['JJ', 'JJR', 'JJS'],\n",
    "    'adv': ['RB', 'RBR', 'RBS', 'WRB']\n",
    "}\n",
    "\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = Reviewsblob.ReviewsBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "\n",
    "df['noun_count'] = df['Reviews'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "df['verb_count'] = df['Reviews'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "df['adj_count'] = df['Reviews'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "df['adv_count'] = df['Reviews'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "df['pron_count'] = df['Reviews'].apply(lambda x: check_pos_tag(x, 'pron'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>count_sent</th>\n",
       "      <th>count_word</th>\n",
       "      <th>count_unique_word</th>\n",
       "      <th>count_letters</th>\n",
       "      <th>word_density</th>\n",
       "      <th>count_punctuations</th>\n",
       "      <th>count_words_upper</th>\n",
       "      <th>count_words_lower</th>\n",
       "      <th>...</th>\n",
       "      <th>alphabetetics</th>\n",
       "      <th>Spaces</th>\n",
       "      <th>words_ends_with_et</th>\n",
       "      <th>words_start_with_no</th>\n",
       "      <th>wordcounts</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>126</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Great': 1, 'move': 1, 'you!': 1, 'job,': 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>159</td>\n",
       "      <td>6.115385</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'much': 1, 'correct': 1, 'find': 1, 'Matthew'...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>64</td>\n",
       "      <td>462</td>\n",
       "      <td>5.775000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'to': 1, 'Wyndham!!': 1, 'highly': 1, 'Lind':...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>78</td>\n",
       "      <td>605</td>\n",
       "      <td>5.550459</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'to': 2, 'servicer': 1, 'started': 1, 'pulled...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>47</td>\n",
       "      <td>341</td>\n",
       "      <td>5.683333</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'am': 1, 'to': 3, 'demeanor': 1, 'during': 1,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars                                            Reviews  count_sent  \\\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...           1   \n",
       "1      5  Matthew Richardson is professional and helpful...           1   \n",
       "2      5  We had a past experience with Wyndham Mortgage...           1   \n",
       "3      5  We have been dealing with Brad Thomka from the...           1   \n",
       "4      5  I can't express how grateful I am for the supp...           1   \n",
       "\n",
       "   count_word  count_unique_word  count_letters  word_density  \\\n",
       "0          19                 19            126      6.300000   \n",
       "1          25                 23            159      6.115385   \n",
       "2          79                 64            462      5.775000   \n",
       "3         108                 78            605      5.550459   \n",
       "4          59                 47            341      5.683333   \n",
       "\n",
       "   count_punctuations  count_words_upper  count_words_lower  ...  \\\n",
       "0                   4                  0                 14  ...   \n",
       "1                   4                  0                 20  ...   \n",
       "2                   8                  0                 64  ...   \n",
       "3                   9                  0                 88  ...   \n",
       "4                   6                  3                 50  ...   \n",
       "\n",
       "   alphabetetics  Spaces  words_ends_with_et  words_start_with_no  \\\n",
       "0             15       0                   0                    0   \n",
       "1             21       0                   0                    0   \n",
       "2             73       0                   0                    1   \n",
       "3            101       0                   0                    1   \n",
       "4             53       0                   0                    1   \n",
       "\n",
       "                                          wordcounts  noun_count  verb_count  \\\n",
       "0  {'Great': 1, 'move': 1, 'you!': 1, 'job,': 1, ...           0           0   \n",
       "1  {'much': 1, 'correct': 1, 'find': 1, 'Matthew'...           0           0   \n",
       "2  {'to': 1, 'Wyndham!!': 1, 'highly': 1, 'Lind':...           0           0   \n",
       "3  {'to': 2, 'servicer': 1, 'started': 1, 'pulled...           0           0   \n",
       "4  {'am': 1, 'to': 3, 'demeanor': 1, 'during': 1,...           0           0   \n",
       "\n",
       "   adj_count  adv_count pron_count  \n",
       "0          0          0          0  \n",
       "1          0          0          0  \n",
       "2          0          0          0  \n",
       "3          0          0          0  \n",
       "4          0          0          0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Sentiment analysis using Textblob module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df[\"Reviews\"].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.453333</td>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.033231</td>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093740</td>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.122289</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nI never write reviews but had to this time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.139815</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nIt all started when Bob G ran a credit che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.071667</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nWhat a horrible experience. We have excell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.176042</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nRep was extremely professional, friendly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.124696</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nI was working with a loan consultant from ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment  Stars                                            Reviews\n",
       "0     0.533333      5  Great job, Wyndham Capital! Each person was pr...\n",
       "1     0.453333      5  Matthew Richardson is professional and helpful...\n",
       "2    -0.033231      5  We had a past experience with Wyndham Mortgage...\n",
       "3     0.093740      5  We have been dealing with Brad Thomka from the...\n",
       "4     0.125000      5  I can't express how grateful I am for the supp...\n",
       "..         ...    ...                                                ...\n",
       "500   0.122289      1  \\r\\nI never write reviews but had to this time...\n",
       "501   0.139815      1  \\r\\nIt all started when Bob G ran a credit che...\n",
       "502   0.071667      1  \\r\\nWhat a horrible experience. We have excell...\n",
       "503   0.176042      1  \\r\\nRep was extremely professional, friendly, ...\n",
       "504   0.124696      1  \\r\\nI was working with a loan consultant from ...\n",
       "\n",
       "[505 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['sentiment','Stars','Reviews']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    410\n",
       "1     95\n",
       "Name: Stars, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Stars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.Reviews\n",
    "y = data.Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378,)\n",
      "(127,)\n",
      "(378,)\n",
      "(127,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>count_sent</th>\n",
       "      <th>count_word</th>\n",
       "      <th>count_unique_word</th>\n",
       "      <th>count_letters</th>\n",
       "      <th>word_density</th>\n",
       "      <th>count_punctuations</th>\n",
       "      <th>count_words_upper</th>\n",
       "      <th>count_words_lower</th>\n",
       "      <th>...</th>\n",
       "      <th>Spaces</th>\n",
       "      <th>words_ends_with_et</th>\n",
       "      <th>words_start_with_no</th>\n",
       "      <th>wordcounts</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>126</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Great': 1, 'move': 1, 'you!': 1, 'job,': 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>159</td>\n",
       "      <td>6.115385</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'much': 1, 'correct': 1, 'find': 1, 'Matthew'...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.453333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>64</td>\n",
       "      <td>462</td>\n",
       "      <td>5.775000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'to': 1, 'Wyndham!!': 1, 'highly': 1, 'Lind':...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.033231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>78</td>\n",
       "      <td>605</td>\n",
       "      <td>5.550459</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'to': 2, 'servicer': 1, 'started': 1, 'pulled...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.093740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>47</td>\n",
       "      <td>341</td>\n",
       "      <td>5.683333</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'am': 1, 'to': 3, 'demeanor': 1, 'during': 1,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars                                            Reviews  count_sent  \\\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...           1   \n",
       "1      5  Matthew Richardson is professional and helpful...           1   \n",
       "2      5  We had a past experience with Wyndham Mortgage...           1   \n",
       "3      5  We have been dealing with Brad Thomka from the...           1   \n",
       "4      5  I can't express how grateful I am for the supp...           1   \n",
       "\n",
       "   count_word  count_unique_word  count_letters  word_density  \\\n",
       "0          19                 19            126      6.300000   \n",
       "1          25                 23            159      6.115385   \n",
       "2          79                 64            462      5.775000   \n",
       "3         108                 78            605      5.550459   \n",
       "4          59                 47            341      5.683333   \n",
       "\n",
       "   count_punctuations  count_words_upper  count_words_lower  ...  Spaces  \\\n",
       "0                   4                  0                 14  ...       0   \n",
       "1                   4                  0                 20  ...       0   \n",
       "2                   8                  0                 64  ...       0   \n",
       "3                   9                  0                 88  ...       0   \n",
       "4                   6                  3                 50  ...       0   \n",
       "\n",
       "   words_ends_with_et  words_start_with_no  \\\n",
       "0                   0                    0   \n",
       "1                   0                    0   \n",
       "2                   0                    1   \n",
       "3                   0                    1   \n",
       "4                   0                    1   \n",
       "\n",
       "                                          wordcounts  noun_count  verb_count  \\\n",
       "0  {'Great': 1, 'move': 1, 'you!': 1, 'job,': 1, ...           0           0   \n",
       "1  {'much': 1, 'correct': 1, 'find': 1, 'Matthew'...           0           0   \n",
       "2  {'to': 1, 'Wyndham!!': 1, 'highly': 1, 'Lind':...           0           0   \n",
       "3  {'to': 2, 'servicer': 1, 'started': 1, 'pulled...           0           0   \n",
       "4  {'am': 1, 'to': 3, 'demeanor': 1, 'during': 1,...           0           0   \n",
       "\n",
       "   adj_count  adv_count  pron_count sentiment  \n",
       "0          0          0           0  0.533333  \n",
       "1          0          0           0  0.453333  \n",
       "2          0          0           0 -0.033231  \n",
       "3          0          0           0  0.093740  \n",
       "4          0          0           0  0.125000  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()   #Text into lower case.\n",
    "    text = text.strip()     #Remove spaces at the beginning and at the end of the string aka. Removing whitespaces.\n",
    "    text = re.sub(r' +', ' ', text)  #Replace substrings\n",
    "    text = re.sub(r\"[-()\\\"#/@;:{}`+=~|.!?,'0-9]\", \"\", text)\n",
    "    return (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def pre_process(text):\n",
    "    #text = text.str.replace('/','')                           #Replacing the / with none\n",
    "    #text = text.apply(lambda x: re.sub(\"  \",\" \", x))          #Replacing double space with single space\n",
    "    #text = re.sub(r\"[-()\\\"#/@;:{}`+=~|.!?,']\", \"\", text)      #Replacing special character with none\n",
    "    #text = re.sub(r'[0-9]+', '', text)                        #Replacing numbers with none\n",
    "    #text = text.apply(lambda x: \" \".join(x.translate(str.maketrans('', '', string.punctuation)) for x in x.split() if x.isalpha()))\n",
    "    text = text.apply(lambda x: \" \".join(x for x in x.split() if x not in stop)) #Removing stop words\n",
    "    #text = text.apply(lambda x: str(TextBlob(x).correct()))                      #Correct spelling corrections\n",
    "    #text = text.apply(lambda x: \" \".join(PorterStemmer().stem(word) for word in x.split())) #Stemming using porter stemmer\n",
    "    #text = text.apply(lambda x: \" \".join(stemmer_func(word) for word in x.split()))        #Stemming\n",
    "    #text = text.apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))   #lemmatization\n",
    "    #text = text.apply(lambda x: \" \".join(word for word, pos in pos_tag(x.split()) if pos not in ['NN','NNS','NNP','NNPS'])) #Removing nouns etc\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(lambda x: clean_text(x))\n",
    "X_test = X_test.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pre_process(X_train)\n",
    "X_test=pre_process(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization (Count, Tfidf, Hashing)\n",
    "    - Charter level\n",
    "    - Word level\n",
    "    - n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "                             ngram_range=(1, 1 ), \n",
    "                             min_df=5, \n",
    "                             encoding='latin-1' ,\n",
    "                             max_features=800)\n",
    "xtrain_count = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<378x596 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9211 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm=xtrain_count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaron',\n",
       " 'able',\n",
       " 'absolutely',\n",
       " 'accept',\n",
       " 'accommodating',\n",
       " 'account',\n",
       " 'accurate',\n",
       " 'across',\n",
       " 'actual',\n",
       " 'adam',\n",
       " 'additional',\n",
       " 'advice',\n",
       " 'agent',\n",
       " 'agreed',\n",
       " 'alex',\n",
       " 'almost',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'always',\n",
       " 'amazing',\n",
       " 'american',\n",
       " 'amount',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'appraisal',\n",
       " 'appraiser',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'approved',\n",
       " 'around',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'aspects',\n",
       " 'attention',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'balance',\n",
       " 'bank',\n",
       " 'banks',\n",
       " 'barrett',\n",
       " 'based',\n",
       " 'became',\n",
       " 'beginning',\n",
       " 'beneficial',\n",
       " 'best',\n",
       " 'better',\n",
       " 'beyond',\n",
       " 'big',\n",
       " 'bob',\n",
       " 'brent',\n",
       " 'broker',\n",
       " 'business',\n",
       " 'buy',\n",
       " 'buyer',\n",
       " 'buyers',\n",
       " 'buying',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'calm',\n",
       " 'came',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'capital',\n",
       " 'care',\n",
       " 'causing',\n",
       " 'certainly',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'check',\n",
       " 'chose',\n",
       " 'chris',\n",
       " 'circumstances',\n",
       " 'clear',\n",
       " 'clients',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closing',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comfortable',\n",
       " 'communicate',\n",
       " 'communicated',\n",
       " 'communication',\n",
       " 'companies',\n",
       " 'company',\n",
       " 'competitive',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'completely',\n",
       " 'complicated',\n",
       " 'comps',\n",
       " 'concerns',\n",
       " 'confident',\n",
       " 'contact',\n",
       " 'contacted',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'contract',\n",
       " 'conventional',\n",
       " 'conversation',\n",
       " 'conversations',\n",
       " 'cost',\n",
       " 'costs',\n",
       " 'could',\n",
       " 'couldnt',\n",
       " 'course',\n",
       " 'credit',\n",
       " 'current',\n",
       " 'customer',\n",
       " 'customers',\n",
       " 'daily',\n",
       " 'dallas',\n",
       " 'date',\n",
       " 'day',\n",
       " 'days',\n",
       " 'deal',\n",
       " 'dealing',\n",
       " 'dealt',\n",
       " 'dean',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'definitely',\n",
       " 'despite',\n",
       " 'detail',\n",
       " 'details',\n",
       " 'didnt',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'dlj',\n",
       " 'documentation',\n",
       " 'documents',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'dream',\n",
       " 'due',\n",
       " 'earlier',\n",
       " 'easier',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'efficient',\n",
       " 'else',\n",
       " 'email',\n",
       " 'emailed',\n",
       " 'emails',\n",
       " 'encountered',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'enough',\n",
       " 'ensure',\n",
       " 'entire',\n",
       " 'escrow',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'exceeded',\n",
       " 'excellent',\n",
       " 'expect',\n",
       " 'expectations',\n",
       " 'expected',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'expertise',\n",
       " 'explain',\n",
       " 'explained',\n",
       " 'explaining',\n",
       " 'extra',\n",
       " 'extremely',\n",
       " 'fact',\n",
       " 'failed',\n",
       " 'family',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'feel',\n",
       " 'fees',\n",
       " 'felt',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'financial',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'finish',\n",
       " 'first',\n",
       " 'five',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'four',\n",
       " 'fred',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'friends',\n",
       " 'full',\n",
       " 'funded',\n",
       " 'future',\n",
       " 'g',\n",
       " 'gave',\n",
       " 'get',\n",
       " 'getting',\n",
       " 'give',\n",
       " 'go',\n",
       " 'going',\n",
       " 'good',\n",
       " 'got',\n",
       " 'great',\n",
       " 'guaranteed',\n",
       " 'guide',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'happier',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'heard',\n",
       " 'help',\n",
       " 'helped',\n",
       " 'helpful',\n",
       " 'helping',\n",
       " 'hesitate',\n",
       " 'high',\n",
       " 'highly',\n",
       " 'hold',\n",
       " 'home',\n",
       " 'homebuyer',\n",
       " 'homes',\n",
       " 'honest',\n",
       " 'honestly',\n",
       " 'hope',\n",
       " 'horrible',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'houses',\n",
       " 'however',\n",
       " 'hung',\n",
       " 'husband',\n",
       " 'i',\n",
       " 'id',\n",
       " 'im',\n",
       " 'immediately',\n",
       " 'impressed',\n",
       " 'including',\n",
       " 'industry',\n",
       " 'information',\n",
       " 'informative',\n",
       " 'informed',\n",
       " 'initial',\n",
       " 'initially',\n",
       " 'institution',\n",
       " 'instructed',\n",
       " 'interest',\n",
       " 'interested',\n",
       " 'issues',\n",
       " 'items',\n",
       " 'ive',\n",
       " 'jason',\n",
       " 'job',\n",
       " 'jocovic',\n",
       " 'joey',\n",
       " 'jon',\n",
       " 'june',\n",
       " 'k',\n",
       " 'keep',\n",
       " 'kept',\n",
       " 'kind',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'knowledge',\n",
       " 'knowledgeable',\n",
       " 'kory',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'least',\n",
       " 'left',\n",
       " 'lender',\n",
       " 'lenders',\n",
       " 'lending',\n",
       " 'less',\n",
       " 'let',\n",
       " 'letter',\n",
       " 'life',\n",
       " 'like',\n",
       " 'line',\n",
       " 'list',\n",
       " 'little',\n",
       " 'll',\n",
       " 'loan',\n",
       " 'loans',\n",
       " 'local',\n",
       " 'lock',\n",
       " 'locked',\n",
       " 'long',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'lot',\n",
       " 'lower',\n",
       " 'made',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'man',\n",
       " 'manner',\n",
       " 'many',\n",
       " 'market',\n",
       " 'may',\n",
       " 'meet',\n",
       " 'messages',\n",
       " 'met',\n",
       " 'mile',\n",
       " 'military',\n",
       " 'minutes',\n",
       " 'missed',\n",
       " 'mistake',\n",
       " 'money',\n",
       " 'month',\n",
       " 'monthly',\n",
       " 'months',\n",
       " 'mortgage',\n",
       " 'mortgages',\n",
       " 'move',\n",
       " 'mr',\n",
       " 'much',\n",
       " 'multiple',\n",
       " 'name',\n",
       " 'nasb',\n",
       " 'nasbs',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'needs',\n",
       " 'never',\n",
       " 'new',\n",
       " 'next',\n",
       " 'night',\n",
       " 'none',\n",
       " 'north',\n",
       " 'notary',\n",
       " 'note',\n",
       " 'nothing',\n",
       " 'number',\n",
       " 'offer',\n",
       " 'offered',\n",
       " 'office',\n",
       " 'officer',\n",
       " 'one',\n",
       " 'online',\n",
       " 'option',\n",
       " 'options',\n",
       " 'oriented',\n",
       " 'original',\n",
       " 'originally',\n",
       " 'overall',\n",
       " 'pacific',\n",
       " 'paid',\n",
       " 'painless',\n",
       " 'paperwork',\n",
       " 'past',\n",
       " 'patient',\n",
       " 'pay',\n",
       " 'payment',\n",
       " 'payments',\n",
       " 'people',\n",
       " 'person',\n",
       " 'personal',\n",
       " 'personally',\n",
       " 'peter',\n",
       " 'phone',\n",
       " 'plan',\n",
       " 'pleasant',\n",
       " 'please',\n",
       " 'pleased',\n",
       " 'pleasure',\n",
       " 'point',\n",
       " 'poor',\n",
       " 'positive',\n",
       " 'possible',\n",
       " 'preapproval',\n",
       " 'pretty',\n",
       " 'previous',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'process',\n",
       " 'processing',\n",
       " 'processor',\n",
       " 'product',\n",
       " 'professional',\n",
       " 'professionalism',\n",
       " 'professionally',\n",
       " 'promised',\n",
       " 'prompt',\n",
       " 'promptly',\n",
       " 'property',\n",
       " 'provide',\n",
       " 'provided',\n",
       " 'purchase',\n",
       " 'purchased',\n",
       " 'purchasing',\n",
       " 'put',\n",
       " 'question',\n",
       " 'questions',\n",
       " 'quick',\n",
       " 'quickly',\n",
       " 'quite',\n",
       " 'rate',\n",
       " 'rates',\n",
       " 'reach',\n",
       " 'reached',\n",
       " 'read',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'really',\n",
       " 'realtor',\n",
       " 'receive',\n",
       " 'received',\n",
       " 'recommend',\n",
       " 'recommended',\n",
       " 'record',\n",
       " 'refi',\n",
       " 'refinance',\n",
       " 'refinanced',\n",
       " 'refinancing',\n",
       " 'reliance',\n",
       " 'rep',\n",
       " 'request',\n",
       " 'requests',\n",
       " 'required',\n",
       " 'respond',\n",
       " 'responded',\n",
       " 'response',\n",
       " 'responses',\n",
       " 'responsive',\n",
       " 'responsiveness',\n",
       " 'returned',\n",
       " 'review',\n",
       " 'reviews',\n",
       " 'right',\n",
       " 's',\n",
       " 'said',\n",
       " 'satisfied',\n",
       " 'saved',\n",
       " 'savings',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'scheduled',\n",
       " 'second',\n",
       " 'see',\n",
       " 'seemed',\n",
       " 'sell',\n",
       " 'send',\n",
       " 'sent',\n",
       " 'service',\n",
       " 'services',\n",
       " 'several',\n",
       " 'showed',\n",
       " 'side',\n",
       " 'sign',\n",
       " 'simple',\n",
       " 'since',\n",
       " 'situation',\n",
       " 'skills',\n",
       " 'smooth',\n",
       " 'smoothly',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'special',\n",
       " 'specifically',\n",
       " 'spent',\n",
       " 'spoke',\n",
       " 'staff',\n",
       " 'star',\n",
       " 'stars',\n",
       " 'start',\n",
       " 'started',\n",
       " 'state',\n",
       " 'status',\n",
       " 'stayed',\n",
       " 'step',\n",
       " 'stephanie',\n",
       " 'steve',\n",
       " 'still',\n",
       " 'stressful',\n",
       " 'suggested',\n",
       " 'super',\n",
       " 'support',\n",
       " 'sure',\n",
       " 'surprises',\n",
       " 'system',\n",
       " 't',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'talk',\n",
       " 'talked',\n",
       " 'talking',\n",
       " 'team',\n",
       " 'tell',\n",
       " 'telling',\n",
       " 'terms',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'thorough',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'thousands',\n",
       " 'three',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'time',\n",
       " 'timely',\n",
       " 'times',\n",
       " 'together',\n",
       " 'told',\n",
       " 'took',\n",
       " 'top',\n",
       " 'total',\n",
       " 'touch',\n",
       " 'transaction',\n",
       " 'tree',\n",
       " 'tried',\n",
       " 'triumph',\n",
       " 'true',\n",
       " 'truly',\n",
       " 'trusted',\n",
       " 'trying',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'types',\n",
       " 'understand',\n",
       " 'understood',\n",
       " 'unlike',\n",
       " 'unpleasant',\n",
       " 'unprofessional',\n",
       " 'upfront',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'using',\n",
       " 'va',\n",
       " 'various',\n",
       " 've',\n",
       " 'veteran',\n",
       " 'via',\n",
       " 'walk',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'wasnt',\n",
       " 'waste',\n",
       " 'way',\n",
       " 'website',\n",
       " 'week',\n",
       " 'weekends',\n",
       " 'weeks',\n",
       " 'well',\n",
       " 'went',\n",
       " 'werent',\n",
       " 'whole',\n",
       " 'wife',\n",
       " 'willing',\n",
       " 'within',\n",
       " 'without',\n",
       " 'wonderful',\n",
       " 'word',\n",
       " 'work',\n",
       " 'worked',\n",
       " 'working',\n",
       " 'works',\n",
       " 'would',\n",
       " 'wouldnt',\n",
       " 'writing',\n",
       " 'wrong',\n",
       " 'wyndham',\n",
       " 'year',\n",
       " 'years',\n",
       " 'yet']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm1=pd.DataFrame(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm1.columns=count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>accommodating</th>\n",
       "      <th>account</th>\n",
       "      <th>accurate</th>\n",
       "      <th>across</th>\n",
       "      <th>actual</th>\n",
       "      <th>adam</th>\n",
       "      <th>...</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>would</th>\n",
       "      <th>wouldnt</th>\n",
       "      <th>writing</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wyndham</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 596 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaron  able  absolutely  accept  accommodating  account  accurate  across  \\\n",
       "0      0     0           0       1              0        0         0       0   \n",
       "1      0     0           0       0              0        0         0       0   \n",
       "2      0     0           0       0              0        0         0       0   \n",
       "3      0     0           0       1              0        0         0       0   \n",
       "4      0     0           0       0              0        0         0       0   \n",
       "\n",
       "   actual  adam  ...  working  works  would  wouldnt  writing  wrong  wyndham  \\\n",
       "0       0     0  ...        0      0      0        1        0      0        0   \n",
       "1       0     0  ...        0      0      0        0        0      0        0   \n",
       "2       0     0  ...        1      0      0        0        0      0        0   \n",
       "3       0     0  ...        0      0      0        1        0      0        0   \n",
       "4       0     0  ...        0      0      0        0        0      0        0   \n",
       "\n",
       "   year  years  yet  \n",
       "0     0      1    0  \n",
       "1     0      0    0  \n",
       "2     0      0    0  \n",
       "3     0      1    0  \n",
       "4     0      0    0  \n",
       "\n",
       "[5 rows x 596 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization (count, tfidf) for both train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "count_vect = CountVectorizer(analyzer='word',\n",
    "                             token_pattern=r'\\w{1,}',\n",
    "                             ngram_range=(1, 1),\n",
    "                             min_df=5,\n",
    "                             encoding='latin-1',\n",
    "                             max_features=800)\n",
    "\n",
    "xtrain_count = count_vect.fit_transform(X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(xtrain_count)\n",
    "\n",
    "#Test\n",
    "#count_vect = CountVectorizer()\n",
    "xtest_count = count_vect.transform(X_test)\n",
    "\n",
    "#tfidf_transformer = TfidfTransformer()\n",
    "X_test_tfidf = tfidf_transformer.transform(xtest_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<127x596 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3089 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm2=pd.DataFrame(X_train_tfidf.toarray(), columns=count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>accommodating</th>\n",
       "      <th>account</th>\n",
       "      <th>accurate</th>\n",
       "      <th>across</th>\n",
       "      <th>actual</th>\n",
       "      <th>adam</th>\n",
       "      <th>...</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>would</th>\n",
       "      <th>wouldnt</th>\n",
       "      <th>writing</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wyndham</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094403</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084774</td>\n",
       "      <td>0.175643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 596 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaron  able  absolutely    accept  accommodating  account  accurate  \\\n",
       "0    0.0   0.0    0.000000  0.133259            0.0      0.0  0.000000   \n",
       "1    0.0   0.0    0.000000  0.000000            0.0      0.0  0.000000   \n",
       "2    0.0   0.0    0.000000  0.000000            0.0      0.0  0.000000   \n",
       "3    0.0   0.0    0.000000  0.130702            0.0      0.0  0.000000   \n",
       "4    0.0   0.0    0.000000  0.000000            0.0      0.0  0.000000   \n",
       "5    0.0   0.0    0.000000  0.000000            0.0      0.0  0.000000   \n",
       "6    0.0   0.0    0.000000  0.000000            0.0      0.0  0.256938   \n",
       "7    0.0   0.0    0.000000  0.000000            0.0      0.0  0.000000   \n",
       "8    0.0   0.0    0.000000  0.000000            0.0      0.0  0.000000   \n",
       "9    0.0   0.0    0.228774  0.000000            0.0      0.0  0.000000   \n",
       "\n",
       "   across  actual  adam  ...   working  works     would   wouldnt  writing  \\\n",
       "0     0.0     0.0   0.0  ...  0.000000    0.0  0.000000  0.123737      0.0   \n",
       "1     0.0     0.0   0.0  ...  0.000000    0.0  0.000000  0.000000      0.0   \n",
       "2     0.0     0.0   0.0  ...  0.194406    0.0  0.000000  0.000000      0.0   \n",
       "3     0.0     0.0   0.0  ...  0.000000    0.0  0.000000  0.121363      0.0   \n",
       "4     0.0     0.0   0.0  ...  0.000000    0.0  0.000000  0.000000      0.0   \n",
       "5     0.0     0.0   0.0  ...  0.000000    0.0  0.084774  0.175643      0.0   \n",
       "6     0.0     0.0   0.0  ...  0.000000    0.0  0.000000  0.000000      0.0   \n",
       "7     0.0     0.0   0.0  ...  0.000000    0.0  0.068074  0.000000      0.0   \n",
       "8     0.0     0.0   0.0  ...  0.000000    0.0  0.000000  0.000000      0.0   \n",
       "9     0.0     0.0   0.0  ...  0.000000    0.0  0.000000  0.000000      0.0   \n",
       "\n",
       "   wrong  wyndham  year     years  yet  \n",
       "0    0.0      0.0   0.0  0.096250  0.0  \n",
       "1    0.0      0.0   0.0  0.000000  0.0  \n",
       "2    0.0      0.0   0.0  0.000000  0.0  \n",
       "3    0.0      0.0   0.0  0.094403  0.0  \n",
       "4    0.0      0.0   0.0  0.000000  0.0  \n",
       "5    0.0      0.0   0.0  0.000000  0.0  \n",
       "6    0.0      0.0   0.0  0.000000  0.0  \n",
       "7    0.0      0.0   0.0  0.000000  0.0  \n",
       "8    0.0      0.0   0.0  0.000000  0.0  \n",
       "9    0.0      0.0   0.0  0.000000  0.0  \n",
       "\n",
       "[10 rows x 596 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word',\n",
    "                                   token_pattern='\\w{1,}',\n",
    "                                   ngram_range=(1, 2),\n",
    "                                   max_features=800)\n",
    "tfidf_vect_ngram.fit(df['Reviews'])\n",
    "xtrain_tfidf_ngram = tfidf_vect_ngram.transform(X_train)\n",
    "xtest_tfidf_ngram = tfidf_vect_ngram.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<378x800 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8051 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfidf_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<127x800 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2835 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest_tfidf_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm3=pd.DataFrame(xtrain_tfidf_ngram.toarray(), columns= tfidf_vect_ngram.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>a</th>\n",
       "      <th>a few</th>\n",
       "      <th>a great</th>\n",
       "      <th>a home</th>\n",
       "      <th>...</th>\n",
       "      <th>would recommend</th>\n",
       "      <th>wouldn</th>\n",
       "      <th>wouldn t</th>\n",
       "      <th>wyndham</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>you are</th>\n",
       "      <th>you can</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1   10    2    3    4    5    a  a few  a great  a home  ...  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0     0.0  ...   \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0     0.0  ...   \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0     0.0  ...   \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0     0.0  ...   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0     0.0  ...   \n",
       "..   ...  ...  ...  ...  ...  ...  ...    ...      ...     ...  ...   \n",
       "373  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0     0.0  ...   \n",
       "374  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0     0.0  ...   \n",
       "375  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0     0.0  ...   \n",
       "376  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0     0.0  ...   \n",
       "377  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0     0.0  ...   \n",
       "\n",
       "     would recommend  wouldn  wouldn t  wyndham  year     years  you  you are  \\\n",
       "0                0.0     0.0       0.0      0.0   0.0  0.112647  0.0      0.0   \n",
       "1                0.0     0.0       0.0      0.0   0.0  0.000000  0.0      0.0   \n",
       "2                0.0     0.0       0.0      0.0   0.0  0.000000  0.0      0.0   \n",
       "3                0.0     0.0       0.0      0.0   0.0  0.109433  0.0      0.0   \n",
       "4                0.0     0.0       0.0      0.0   0.0  0.000000  0.0      0.0   \n",
       "..               ...     ...       ...      ...   ...       ...  ...      ...   \n",
       "373              0.0     0.0       0.0      0.0   0.0  0.000000  0.0      0.0   \n",
       "374              0.0     0.0       0.0      0.0   0.0  0.000000  0.0      0.0   \n",
       "375              0.0     0.0       0.0      0.0   0.0  0.000000  0.0      0.0   \n",
       "376              0.0     0.0       0.0      0.0   0.0  0.000000  0.0      0.0   \n",
       "377              0.0     0.0       0.0      0.0   0.0  0.000000  0.0      0.0   \n",
       "\n",
       "     you can  your  \n",
       "0        0.0   0.0  \n",
       "1        0.0   0.0  \n",
       "2        0.0   0.0  \n",
       "3        0.0   0.0  \n",
       "4        0.0   0.0  \n",
       "..       ...   ...  \n",
       "373      0.0   0.0  \n",
       "374      0.0   0.0  \n",
       "375      0.0   0.0  \n",
       "376      0.0   0.0  \n",
       "377      0.0   0.0  \n",
       "\n",
       "[378 rows x 800 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment=X_train.apply(lambda x:sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentimnet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>started bob g ran credit check without knowled...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>great website knowledgeable responsive always ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>pleasure working robert first call kept well i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>started bob g ran credit check without knowled...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>agree star review easy clear work hello knowle...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>vanessa word fantastic every step way perfect ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>fast easy leave comforts home steven shatz fri...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>friend mine told refinanced house unbelievable...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>worked jon barrett processing refinance loan q...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>peter team great work professional prompt resp...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentimnet\n",
       "501  started bob g ran credit check without knowled...  positive\n",
       "172  great website knowledgeable responsive always ...  positive\n",
       "80   pleasure working robert first call kept well i...  positive\n",
       "46   started bob g ran credit check without knowled...  positive\n",
       "318  agree star review easy clear work hello knowle...  positive\n",
       "..                                                 ...       ...\n",
       "255  vanessa word fantastic every step way perfect ...  positive\n",
       "72   fast easy leave comforts home steven shatz fri...  positive\n",
       "396  friend mine told refinanced house unbelievable...  positive\n",
       "235  worked jon barrett processing refinance loan q...  positive\n",
       "37   peter team great work professional prompt resp...  positive\n",
       "\n",
       "[378 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=pd.concat([X_train,sentiment],axis=1)\n",
    "a.columns=['review','sentimnet']\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    338\n",
       "negative     28\n",
       "neutral      12\n",
       "Name: sentimnet, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sentimnet.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentimnet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>started bob g ran credit check without knowled...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>great website knowledgeable responsive always ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>pleasure working robert first call kept well i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>started bob g ran credit check without knowled...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>agree star review easy clear work hello knowle...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>vanessa word fantastic every step way perfect ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>fast easy leave comforts home steven shatz fri...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>friend mine told refinanced house unbelievable...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>worked jon barrett processing refinance loan q...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>peter team great work professional prompt resp...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentimnet\n",
       "501  started bob g ran credit check without knowled...  positive\n",
       "172  great website knowledgeable responsive always ...  positive\n",
       "80   pleasure working robert first call kept well i...  positive\n",
       "46   started bob g ran credit check without knowled...  positive\n",
       "318  agree star review easy clear work hello knowle...  positive\n",
       "..                                                 ...       ...\n",
       "255  vanessa word fantastic every step way perfect ...  positive\n",
       "72   fast easy leave comforts home steven shatz fri...  positive\n",
       "396  friend mine told refinanced house unbelievable...  positive\n",
       "235  worked jon barrett processing refinance loan q...  positive\n",
       "37   peter team great work professional prompt resp...  positive\n",
       "\n",
       "[338 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#positive reviews\n",
    "a[a.sentimnet=='positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentimnet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>use reliance first capitoldo let kenneth watso...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>jason chandler team worked hard ensure able pu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>based results give star initial conversations ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>team aware critical information delayed refina...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>new federal regulations made tedious time cons...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>applied three different lenders two came acros...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>aweful experience terms service followup overa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>wesley white worked tirelessly patiently get l...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>miserable experience screwed everything imagin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>bad</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>arbor mortgage failed ways list government shu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>lisa podorson set closing date three different...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>lender contacted previous phone number list re...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>lender contacted previous phone number list re...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>hesitant use nonlocal mortgage company loan of...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>spoke lender quite time gave information neede...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>increased rate quoted different closing costs ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>never write reviews time prevent anyone making...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>awful experience reliance refinancing home wou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>miserable experience screwed everything imagin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>slight difficulty online documents signing</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>able provide viable product needs rude confuse...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>past experience wyndham mortgage would without...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>unfortunately dealing agent santa clara county...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>lender contacted previous phone number list re...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>hesitant use nonlocal mortgage company loan of...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>called seconds submitting lending tree form as...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>mike bestalways questions closed loan weeks wo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentimnet\n",
       "93   use reliance first capitoldo let kenneth watso...  negative\n",
       "364  jason chandler team worked hard ensure able pu...  negative\n",
       "98   based results give star initial conversations ...  negative\n",
       "91   team aware critical information delayed refina...  negative\n",
       "59   new federal regulations made tedious time cons...  negative\n",
       "157  applied three different lenders two came acros...  negative\n",
       "411  aweful experience terms service followup overa...  negative\n",
       "88   wesley white worked tirelessly patiently get l...  negative\n",
       "492  miserable experience screwed everything imagin...  negative\n",
       "401                                                bad  negative\n",
       "409  arbor mortgage failed ways list government shu...  negative\n",
       "100  lisa podorson set closing date three different...  negative\n",
       "227  lender contacted previous phone number list re...  negative\n",
       "44   lender contacted previous phone number list re...  negative\n",
       "476  hesitant use nonlocal mortgage company loan of...  negative\n",
       "414  spoke lender quite time gave information neede...  negative\n",
       "234  increased rate quoted different closing costs ...  negative\n",
       "45   never write reviews time prevent anyone making...  negative\n",
       "103  awful experience reliance refinancing home wou...  negative\n",
       "220  miserable experience screwed everything imagin...  negative\n",
       "148         slight difficulty online documents signing  negative\n",
       "412  able provide viable product needs rude confuse...  negative\n",
       "2    past experience wyndham mortgage would without...  negative\n",
       "405  unfortunately dealing agent santa clara county...  negative\n",
       "499  lender contacted previous phone number list re...  negative\n",
       "215  hesitant use nonlocal mortgage company loan of...  negative\n",
       "413  called seconds submitting lending tree form as...  negative\n",
       "390  mike bestalways questions closed loan weeks wo...  negative"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#negative reviews\n",
    "a[a.sentimnet=='negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentimnet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>closing process va loan went smoothly loan ser...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>rate relockin rule followed</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>bob triumph beat lenders rates prompt approval...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>informative responsive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>lending tree matching companies dont offer pro...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>called asked city nh looking told might consid...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>closing process va loan went smoothly loan ser...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>person spoke kept interrupting telling line ra...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>informative responsive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>teddy represents company well communicative pa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>teddy represents company well communicative pa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>closing process va loan went smoothly loan ser...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentimnet\n",
       "39   closing process va loan went smoothly loan ser...   neutral\n",
       "236                        rate relockin rule followed   neutral\n",
       "286  bob triumph beat lenders rates prompt approval...   neutral\n",
       "70                              informative responsive   neutral\n",
       "408  lending tree matching companies dont offer pro...   neutral\n",
       "417  called asked city nh looking told might consid...   neutral\n",
       "219  closing process va loan went smoothly loan ser...   neutral\n",
       "97   person spoke kept interrupting telling line ra...   neutral\n",
       "60                              informative responsive   neutral\n",
       "74   teddy represents company well communicative pa...   neutral\n",
       "64   teddy represents company well communicative pa...   neutral\n",
       "491  closing process va loan went smoothly loan ser...   neutral"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#neutral reviews\n",
    "a[a.sentimnet=='neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create user defined function for train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid,\n",
    "                valid_y):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "\n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "\n",
    "    return metrics.accuracy_score(classifier.predict(feature_vector_train),\n",
    "                                  label), metrics.accuracy_score(\n",
    "                                      predictions, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building different models with different vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[  1   5]\n",
      " [ 70 308]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[  1   5]\n",
      " [308 308]]\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=123)\n",
    "\n",
    "X_train_tfidf_os, y_train_tfidf_os = ros.fit_sample(X_train_tfidf, y_train)\n",
    "\n",
    "X_train_cnt_os, y_train_cnt_os = ros.fit_sample(xtrain_count, y_train)\n",
    "\n",
    "X_train_tfidf_ngram_os, y_train_tfidf_ngram_os = ros.fit_sample(xtrain_tfidf_ngram, y_train)\n",
    "\n",
    "unique_elements, counts_elements = np.unique(y_train_tfidf_os, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB  for L1, Count Vectors:  (0.9756493506493507, 0.952755905511811)\n",
      "NB  for L1, WordLevel TF-IDF:  (0.9724025974025974, 0.9606299212598425)\n",
      "NB  for L1, N-Gram Vectors:  (0.9675324675324676, 0.9448818897637795)\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "# Naive Bayes on TF-IDF\n",
    "accuracy_L1 = train_model(naive_bayes.MultinomialNB(), X_train_tfidf_os, y_train_tfidf_os, X_test_tfidf, y_test)\n",
    "print(\"NB  for L1, Count Vectors: \", accuracy_L1)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy_L1 = train_model(naive_bayes.MultinomialNB(), X_train_cnt_os, y_train_cnt_os, xtest_count, y_test)\n",
    "print(\"NB  for L1, WordLevel TF-IDF: \", accuracy_L1)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy_L1 = train_model(naive_bayes.MultinomialNB(), X_train_tfidf_ngram_os, y_train_tfidf_ngram_os, xtest_tfidf_ngram, y_test)\n",
    "print(\"NB  for L1, N-Gram Vectors: \", accuracy_L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  for L1, Count Vectors:  (0.9837662337662337, 0.968503937007874)\n",
      "LR  for L1, WordLevel TF-IDF:  (0.9983766233766234, 0.9763779527559056)\n",
      "LR  for L1, N-Gram Vectors:  (0.9756493506493507, 0.9606299212598425)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "# Logistic Regression on Count Vectors and TF-IDF\n",
    "accuracy_L1 = train_model(LogisticRegression(), X_train_tfidf_os, y_train_tfidf_os, X_test_tfidf, y_test)\n",
    "print(\"LR  for L1, Count Vectors: \", accuracy_L1)\n",
    "\n",
    "\n",
    "\n",
    "# Logistic Regression on Word Level TF IDF Vectors\n",
    "accuracy_L1 = train_model(LogisticRegression(), X_train_cnt_os, y_train_cnt_os, xtest_count, y_test)\n",
    "print(\"LR  for L1, WordLevel TF-IDF: \", accuracy_L1)\n",
    "\n",
    "\n",
    "\n",
    "# Logistic Regression on Ngram Level TF IDF Vectors\n",
    "accuracy_L1 = train_model(LogisticRegression(), X_train_tfidf_ngram_os, y_train_tfidf_ngram_os, xtest_tfidf_ngram, y_test)\n",
    "print(\"LR  for L1, N-Gram Vectors: \", accuracy_L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC  for L1, Count Vectors:  (0.9983766233766234, 0.937007874015748)\n",
      "SVC  for L1, WordLevel TF-IDF:  (0.9756493506493507, 0.9448818897637795)\n",
      "SVC  for L1, N-Gram Vectors:  (0.9983766233766234, 0.9448818897637795)\n"
     ]
    }
   ],
   "source": [
    "#Linear SVC\n",
    "# Linear SVC on Count Vectors and TF-IDF\n",
    "accuracy_L1 = train_model(SVC(), X_train_tfidf_os, y_train_tfidf_os,\n",
    "                          X_test_tfidf, y_test)\n",
    "print(\"SVC  for L1, Count Vectors: \", accuracy_L1)\n",
    "\n",
    "# Linear SVC on Word Level TF IDF Vectors\n",
    "accuracy_L1 = train_model(SVC(), X_train_cnt_os, y_train_cnt_os, xtest_count,\n",
    "                          y_test)\n",
    "print(\"SVC  for L1, WordLevel TF-IDF: \", accuracy_L1)\n",
    "\n",
    "# Linear SVC on Ngram Level TF IDF Vectors\n",
    "accuracy_L1 = train_model(SVC(), X_train_tfidf_ngram_os,\n",
    "                          y_train_tfidf_ngram_os, xtest_tfidf_ngram, y_test)\n",
    "print(\"SVC  for L1, N-Gram Vectors: \", accuracy_L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we are getting best score from logistic regression. so we will chose this for predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgm=LogisticRegression().fit( X_train_cnt_os, y_train_cnt_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983766233766234"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgm.score( X_train_cnt_os, y_train_cnt_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lgm.predict(xtest_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 1, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 1, 5,\n",
       "       5, 1, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 5, 5, 1, 5, 5, 5,\n",
       "       1, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5,\n",
       "       1, 5, 5, 5, 5, 5, 5, 5, 1, 5, 1, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 1,\n",
       "       5, 5, 5, 5, 5, 5, 5, 1, 1, 5, 5, 5, 1, 5, 5, 1, 5], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame( { 'actual':  y_test,\n",
    "                                'predicted':test_pred} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  predicted\n",
       "307       5          5\n",
       "343       5          5\n",
       "47        1          1\n",
       "67        5          5\n",
       "361       5          5\n",
       "..      ...        ...\n",
       "41        1          1\n",
       "360       5          5\n",
       "289       5          5\n",
       "497       1          1\n",
       "293       5          5\n",
       "\n",
       "[127 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9763779527559056\n",
      "0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(metrics.accuracy_score(pred.actual, pred.predicted))\n",
    "print(metrics.roc_auc_score(pred.actual, pred.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 22,   0],\n",
       "       [  3, 102]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_pred.predicted, y_pred.actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we are getting accuracy of 97% in the predictions from the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
